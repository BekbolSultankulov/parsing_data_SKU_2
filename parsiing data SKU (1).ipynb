{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://retailcontentservice.com/catalog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import time\n",
    "from itertools import groupby\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "headers={\n",
    "    \n",
    "    }\n",
    "\n",
    "def get_links(url):\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text,'lxml')\n",
    "    links=soup.find_all('a',class_='btn-block')\n",
    "    main_links=[]\n",
    "    \n",
    "    for i in links:\n",
    "        main_links.append(str('https://retailcontentservice.com')+str(i.get('href')))\n",
    "#     print(main_links[1:16])\n",
    "    result=[]\n",
    "    \n",
    "    for j in main_links[1:16]:       \n",
    "        response=requests.get(j)\n",
    "        soup=BeautifulSoup(response.text,'lxml')\n",
    "        links=soup.find('ul',class_='link-list link-list_md').find_all('li')\n",
    "        category=soup.find('h1').text.strip()\n",
    "        sub_category=[]\n",
    "        second_links=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in links:\n",
    "            second_links.append(str('https://retailcontentservice.com')+str(i.find('a').get('href')))\n",
    "            sub_category.append(i.find('a').text.strip())\n",
    "            \n",
    "        for i in range(len(second_links)):\n",
    "            result.append({\n",
    "                'category':category,\n",
    "                'sub_category':sub_category[i],\n",
    "                'links':second_links[i]\n",
    "                \n",
    "                \n",
    "                \n",
    "            })\n",
    "        \n",
    "            \n",
    "    result2=[]\n",
    "    for i in result:\n",
    "        response=requests.get(i.get('links'))\n",
    "        soup=BeautifulSoup(response.text,'lxml')\n",
    "        links2=soup.find('ul',class_='link-list link-list_md').find_all('li')\n",
    "        second_links2=[]\n",
    "        sub_category2=[]\n",
    "        for j in links2:\n",
    "            second_links2.append(str('https://retailcontentservice.com')+str(j.find('a').get('href')))\n",
    "            sub_category2.append(j.find('a').text.strip())\n",
    "        \n",
    "        for k in range(len(second_links2)):\n",
    "            \n",
    "            result2.append({                \n",
    "            'category':i.get('category'),\n",
    "            'sub_category':i.get('sub_category'),\n",
    "            'sub_sub_category':sub_category2[k],     \n",
    "            'links':second_links2[k]          \n",
    "                       \n",
    "        })\n",
    "    \n",
    "    with open(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\barcode\\retailcontentservice.com\\main_url.json','w',encoding='utf-8') as file:\n",
    "                json.dump(result2,file,indent=4,ensure_ascii=False)        \n",
    "            \n",
    "def collect_data(file_path):\n",
    "    data = json.load(open(file_path,'r', encoding='utf-8'))\n",
    "    result=[]\n",
    "    \n",
    "    for i in data:\n",
    "        links=[]\n",
    "        \n",
    "        for j in range(1,20):\n",
    "            \n",
    "            response=requests.get(str(i.get('links'))+'page'+str(j)+'/',headers=headers)\n",
    "            soup=BeautifulSoup(response.text,'lxml')\n",
    "            link=soup.find_all('div',class_='catalog__grid-view__item products-slider__item col-sm-6 wrap wrap-sm-2 col-lg-4 wrap-lg-3')\n",
    "            \n",
    "            if link!=None:\n",
    "                for k in link:\n",
    "                    links.append(str('https://retailcontentservice.com/')+str(k.find('a').get('href')))\n",
    "            else:                \n",
    "                break\n",
    "        for k in range(len(links)):\n",
    "            result.append({                \n",
    "            'category':i.get('category'),\n",
    "            'sub_category':i.get('sub_category'),\n",
    "            'sub_sub_category':i.get('sub_sub_category'),     \n",
    "            'links':links[k]          \n",
    "                       \n",
    "        })\n",
    "    with open(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\barcode\\retailcontentservice.com\\url.json','w',encoding='utf-8') as file:\n",
    "                json.dump(result,file,indent=4,ensure_ascii=False)  \n",
    "                \n",
    "def collect_all_dates(file_path):\n",
    "    result=[]\n",
    "    data = json.load(open(file_path,'r', encoding='utf-8'))\n",
    "    for i in data[:20]:\n",
    "        response=requests.get(i.get('links'),headers=headers)\n",
    "        soup=BeautifulSoup(response.text,'lxml')        \n",
    "        titles=[]\n",
    "        brands=[]\n",
    "        producers=[]\n",
    "        barcodes=[]\n",
    "        try:\n",
    "            titles.append(soup.find('h1').text.strip())\n",
    "        except:\n",
    "            titles.append(None)\n",
    "\n",
    "        try:\n",
    "            brand=soup.find_all('ul',class_='list-unstyled list-lg-pad')\n",
    "            for j in brand:\n",
    "                brands.append(j.find('li').text)\n",
    "        except:\n",
    "            brands.append(None)\n",
    "            \n",
    "        try:\n",
    "            barcode=soup.find_all(class_='col-xs-6 col-sm-6 col-md-6 col-lg-12 bcTarget')\n",
    "            for k in barcode:\n",
    "                barcodes.append(k.get('gtin'))\n",
    "        except:\n",
    "            barcodes.append(None)\n",
    "            \n",
    "        try:\n",
    "            producers.append(soup.find('div',class_='wrap-name-main-merchant').text.strip())\n",
    "        except:\n",
    "            producers.append(None)\n",
    "            \n",
    "        \n",
    "        result.append({ \n",
    "            'name':titles[0],\n",
    "            'barcode':barcodes,\n",
    "            'brand':brands[0],\n",
    "            'producer':producers[0],\n",
    "            'category':i.get('category'),\n",
    "            'sub_category':i.get('sub_category'),\n",
    "            'sub_sub_category':i.get('sub_sub_category'),     \n",
    "            'links':i.get('links')         \n",
    "                       \n",
    "        })\n",
    "    with open(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\barcode\\retailcontentservice.com\\all_data.json','w',encoding='utf-8') as file:\n",
    "                json.dump(result,file,indent=4,ensure_ascii=False)  \n",
    "            \n",
    "            \n",
    "\n",
    "def main():\n",
    "    #get_links('https://retailcontentservice.com/catalog/')\n",
    "    #collect_data(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\barcode\\retailcontentservice.com\\main_url.json')\n",
    "    collect_all_dates(r'C:\\Users\\svnduw\\Desktop\\Bekbol\\Bekbol project\\barcode\\retailcontentservice.com\\url.json')\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
